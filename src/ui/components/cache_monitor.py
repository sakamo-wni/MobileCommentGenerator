"""
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çµ±è¨ˆæƒ…å ±ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¯è¦–åŒ–ã™ã‚‹
Streamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
"""

from __future__ import annotations

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import json
from pathlib import Path

from src.utils.cache_manager import get_cache_manager
from src.types.aliases import JsonDict


def display_cache_monitor(show_details: bool = True):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¢ãƒ‹ã‚¿ãƒ¼ã‚’è¡¨ç¤º"""
    st.header("ğŸ—„ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¢ãƒ‹ã‚¿ãƒ¼")
    
    cache_manager = get_cache_manager()
    
    # æ›´æ–°ãƒœã‚¿ãƒ³
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("ğŸ”„ æ›´æ–°", key="refresh_cache_stats"):
            st.rerun()
    
    # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
    display_cache_summary(cache_manager)
    
    # è©³ç´°çµ±è¨ˆ
    if show_details:
        display_cache_details(cache_manager)
    
    # å±¥æ­´ã‚°ãƒ©ãƒ•
    display_cache_history()


def display_cache_summary(cache_manager):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    stats = cache_manager.get_stats_summary()
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ç·ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ•°",
            stats["total_caches"],
            help="ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç·æ•°"
        )
    
    with col2:
        st.metric(
            "ç·ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡",
            f"{stats['total_memory_usage_mb']:.1f} MB",
            help="å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆè¨ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡"
        )
    
    with col3:
        hit_rate_percent = stats['overall_hit_rate'] * 100
        st.metric(
            "å…¨ä½“ãƒ’ãƒƒãƒˆç‡",
            f"{hit_rate_percent:.1f}%",
            help="å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å¹³å‡ãƒ’ãƒƒãƒˆç‡"
        )
    
    with col4:
        memory_pressure = stats['memory_pressure'] * 100
        delta_color = "inverse" if memory_pressure > 80 else "normal"
        st.metric(
            "ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼",
            f"{memory_pressure:.1f}%",
            delta=f"{memory_pressure - 50:.1f}%",
            delta_color=delta_color,
            help="ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡"
        )


def display_cache_details(cache_manager):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥è©³ç´°")
    
    all_stats = cache_manager.get_all_stats()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    cache_data = []
    for name, stats in all_stats.items():
        cache_data.append({
            "ã‚­ãƒ£ãƒƒã‚·ãƒ¥å": name,
            "ã‚¨ãƒ³ãƒˆãƒªæ•°": stats.basic_stats.size,
            "ãƒ’ãƒƒãƒˆæ•°": stats.basic_stats.hits,
            "ãƒŸã‚¹æ•°": stats.basic_stats.misses,
            "ãƒ’ãƒƒãƒˆç‡": f"{stats.basic_stats.hit_rate * 100:.1f}%",
            "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡(MB)": f"{stats.basic_stats.memory_usage_bytes / (1024 * 1024):.2f}",
            "åŠ¹ç‡ã‚¹ã‚³ã‚¢": f"{stats.cache_efficiency_score:.2f}",
            "LRUå‰Šé™¤æ•°": stats.evictions_by_lru,
            "ãƒ¡ãƒ¢ãƒªåœ§è¿«å‰Šé™¤æ•°": stats.evictions_by_memory_pressure,
        })
    
    df = pd.DataFrame(cache_data)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "åŠ¹ç‡ã‚¹ã‚³ã‚¢": st.column_config.ProgressColumn(
                "åŠ¹ç‡ã‚¹ã‚³ã‚¢",
                help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç·åˆçš„ãªåŠ¹ç‡æ€§ï¼ˆ0-1ï¼‰",
                format="%.2f",
                min_value=0,
                max_value=1,
            ),
        }
    )
    
    # å€‹åˆ¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è©³ç´°è¡¨ç¤º
    selected_cache = st.selectbox(
        "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’é¸æŠ",
        options=list(all_stats.keys()),
        key="selected_cache_detail"
    )
    
    if selected_cache:
        display_single_cache_detail(selected_cache, all_stats[selected_cache])


def display_single_cache_detail(cache_name: str, stats):
    """å˜ä¸€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è©³ç´°ã‚’è¡¨ç¤º"""
    col1, col2 = st.columns(2)
    
    with col1:
        # ãƒ’ãƒƒãƒˆç‡ã®ã‚²ãƒ¼ã‚¸ãƒãƒ£ãƒ¼ãƒˆ
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = stats.basic_stats.hit_rate * 100,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': f"{cache_name} ãƒ’ãƒƒãƒˆç‡ (%)"},
            delta = {'reference': 80},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkgreen"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgray"},
                    {'range': [50, 80], 'color': "gray"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ç†ç”±ã®å††ã‚°ãƒ©ãƒ•
        eviction_data = {
            "TTLæœŸé™åˆ‡ã‚Œ": stats.evictions_by_ttl,
            "LRU": stats.evictions_by_lru,
            "ãƒ¡ãƒ¢ãƒªåœ§è¿«": stats.evictions_by_memory_pressure,
        }
        
        if sum(eviction_data.values()) > 0:
            fig = px.pie(
                values=list(eviction_data.values()),
                names=list(eviction_data.keys()),
                title=f"{cache_name} ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ç†ç”±"
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ã¯ã¾ã ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“")
    
    # ã‚¨ãƒ³ãƒˆãƒªã®å¹´é½¢æƒ…å ±
    if stats.basic_stats.oldest_entry_age_seconds:
        st.info(
            f"æœ€å¤ã‚¨ãƒ³ãƒˆãƒª: {stats.basic_stats.oldest_entry_age_seconds / 60:.1f}åˆ†å‰ | "
            f"æœ€æ–°ã‚¨ãƒ³ãƒˆãƒª: {stats.basic_stats.newest_entry_age_seconds / 60:.1f}åˆ†å‰"
        )


def display_cache_history():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥å±¥æ­´ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´")
    
    # çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    stats_file = Path("cache_stats.json")
    
    if not stats_file.exists():
        st.info("å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
        return
    
    try:
        with open(stats_file, 'r') as f:
            history = json.load(f)
    except Exception as e:
        st.error(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return
    
    if not history:
        st.info("å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df_history = pd.DataFrame(history)
    df_history['timestamp'] = pd.to_datetime(df_history['timestamp'])
    
    # æ™‚é–“ç¯„å›²ã®é¸æŠ
    time_range = st.select_slider(
        "è¡¨ç¤ºæœŸé–“",
        options=["1æ™‚é–“", "6æ™‚é–“", "24æ™‚é–“", "7æ—¥é–“"],
        value="24æ™‚é–“",
        key="cache_history_range"
    )
    
    # æ™‚é–“ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿
    now = datetime.now()
    time_ranges = {
        "1æ™‚é–“": timedelta(hours=1),
        "6æ™‚é–“": timedelta(hours=6),
        "24æ™‚é–“": timedelta(hours=24),
        "7æ—¥é–“": timedelta(days=7),
    }
    
    cutoff_time = now - time_ranges[time_range]
    df_filtered = df_history[df_history['timestamp'] >= cutoff_time]
    
    if df_filtered.empty:
        st.info(f"é¸æŠã—ãŸæœŸé–“ï¼ˆ{time_range}ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    tab1, tab2, tab3 = st.tabs(["ãƒ’ãƒƒãƒˆç‡", "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", "ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°"])
    
    with tab1:
        fig = px.line(
            df_filtered,
            x='timestamp',
            y='overall_hit_rate',
            title='å…¨ä½“ãƒ’ãƒƒãƒˆç‡ã®æ¨ç§»',
            labels={'overall_hit_rate': 'ãƒ’ãƒƒãƒˆç‡', 'timestamp': 'æ™‚åˆ»'}
        )
        fig.update_yaxis(tickformat='.0%')
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        fig = px.line(
            df_filtered,
            x='timestamp',
            y='total_memory_usage_mb',
            title='ç·ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨ç§»',
            labels={'total_memory_usage_mb': 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)', 'timestamp': 'æ™‚åˆ»'}
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        fig = px.line(
            df_filtered,
            x='timestamp',
            y='total_requests',
            title='ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã®æ¨ç§»',
            labels={'total_requests': 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°', 'timestamp': 'æ™‚åˆ»'}
        )
        st.plotly_chart(fig, use_container_width=True)


def cache_control_panel():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶å¾¡ãƒ‘ãƒãƒ«"""
    st.subheader("âš™ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶å¾¡")
    
    cache_manager = get_cache_manager()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ—‘ï¸ å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", type="secondary"):
            cache_manager.clear_all_caches()
            st.success("å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()
    
    with col2:
        selected_cache = st.selectbox(
            "å€‹åˆ¥ã‚¯ãƒªã‚¢",
            options=list(cache_manager._caches.keys()),
            key="clear_single_cache"
        )
    
    with col3:
        if st.button("ğŸ—‘ï¸ é¸æŠã—ãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"):
            if selected_cache:
                cache_manager.get_cache(selected_cache).clear()
                st.success(f"{selected_cache} ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                st.rerun()