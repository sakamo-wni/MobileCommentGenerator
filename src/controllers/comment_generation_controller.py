"""ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼"""

import asyncio
import logging
from typing import List, Dict, Optional, Callable
from concurrent.futures import as_completed, ThreadPoolExecutor

from src.config.app_config import AppConfig, get_config
from src.types import LocationResult, BatchGenerationResult
from src.ui.streamlit_utils import load_history, load_locations, save_to_history
from src.utils.error_handler import ErrorHandler
from src.workflows.comment_generation_workflow import run_comment_generation
from src.controllers.metadata_extractor import MetadataExtractor
from src.controllers.validators import ValidationManager
from src.controllers.batch_processor import BatchProcessor
from src.controllers.progress_handler import ProgressHandler
from app_interfaces import ICommentGenerationController

logger = logging.getLogger(__name__)


class CommentGenerationController(ICommentGenerationController):
    """ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç®¡ç†ã™ã‚‹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self, config: Optional[AppConfig] = None):
        self._config = config or get_config()
        self._generation_history: Optional[List[Dict[str, str]]] = None
        
        # ä¾å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self._metadata_extractor = MetadataExtractor()
        self._validators = ValidationManager(self._config)
        self._progress_handler = ProgressHandler(self._metadata_extractor)
        self._batch_processor = BatchProcessor(self._progress_handler)
    
    @property
    def config(self) -> AppConfig:
        """è¨­å®šã‚’å–å¾—"""
        return self._config
    
    @property
    def generation_history(self) -> List[Dict[str, str]]:
        """ç”Ÿæˆå±¥æ­´ã‚’å–å¾—ï¼ˆé…å»¶èª­ã¿è¾¼ã¿ï¼‰"""
        if self._generation_history is None:
            self._generation_history = load_history()
        return self._generation_history
    
    def get_default_locations(self) -> List[str]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åœ°ç‚¹ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return load_locations()
    
    def get_default_llm_provider(self) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—"""
        return self.config.ui_settings.default_llm_provider
    
    def validate_configuration(self) -> Dict[str, bool | str]:
        """è¨­å®šã®æ¤œè¨¼"""
        return self._validators.validate_configuration()
    
    def get_config_dict(self) -> Dict[str, str | int | float | bool]:
        """è¨­å®šã‚’è¾æ›¸å½¢å¼ã§å–å¾—"""
        return self.config.to_dict()
    
    def generate_comment_for_location(self, location: str, llm_provider: str) -> LocationResult:
        """å˜ä¸€åœ°ç‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"""
        try:
            # å®Ÿéš›ã®ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
            result = run_comment_generation(
                location_name=location,
                target_datetime=None,
                llm_provider=llm_provider
            )
            
            # çµæœã‚’åé›†
            location_result: LocationResult = {
                'location': location,
                'result': result,
                'success': result.get('success', False),
                'comment': result.get('final_comment', ''),
                'error': result.get('error', None),
                'source_files': None
            }
            
            # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æŠ½å‡º
            metadata = result.get('generation_metadata', {})
            if metadata.get('selected_past_comments'):
                sources = []
                for comment in metadata['selected_past_comments']:
                    if 'source_file' in comment:
                        sources.append(comment['source_file'])
                if sources:
                    location_result['source_files'] = sources
                    # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
                    logger.info(f"åœ°ç‚¹: {location}")
                    logger.info(f"  å¤©æ°—: {metadata.get('weather_condition', 'ä¸æ˜')}")
                    logger.info(f"  æ°—æ¸©: {metadata.get('temperature', 'ä¸æ˜')}Â°C")
                    logger.info(f"  ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«: {sources}")
                    logger.info(f"  ç”Ÿæˆã‚³ãƒ¡ãƒ³ãƒˆ: {result.get('final_comment', '')}")
            
            # å±¥æ­´ã«ä¿å­˜
            if result.get('success'):
                save_to_history(result, location, llm_provider)
                # å±¥æ­´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                self._generation_history = None
            
            return location_result
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            return ErrorHandler.create_error_result(location, e)
    
    def generate_comments_batch(
        self, 
        locations: List[str], 
        llm_provider: str,
        progress_callback: Optional[Callable[[int, int, str], None]] = None, 
        max_workers: int = 3
    ) -> BatchGenerationResult:
        """è¤‡æ•°åœ°ç‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰"""
        # asyncioç‰ˆã‚’è©¦ã™ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å†…ã§ã¯åŒæœŸç‰ˆã‚’ä½¿ç”¨
                return self._batch_processor.process_batch_sync(
                    locations, llm_provider, 
                    self.generate_comment_for_location,
                    progress_callback, max_workers
                )
            else:
                # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã§éåŒæœŸç‰ˆã‚’å®Ÿè¡Œ
                return asyncio.run(
                    self._batch_processor.process_batch_async(
                        locations, llm_provider,
                        self.generate_comment_for_location,
                        progress_callback, max_workers
                    )
                )
        except RuntimeError:
            # asyncioãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯åŒæœŸç‰ˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._batch_processor.process_batch_sync(
                locations, llm_provider,
                self.generate_comment_for_location,
                progress_callback, max_workers
            )
    
    def format_forecast_time(self, forecast_time: str) -> str:
        """äºˆå ±æ™‚åˆ»ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return self._metadata_extractor.format_forecast_time(forecast_time)
    
    def extract_weather_metadata(self, result: LocationResult) -> Dict[str, str | float | None]:
        """çµæœã‹ã‚‰å¤©æ°—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        return self._metadata_extractor.extract_weather_metadata(result)
    
    def validate_location_count(self, locations: List[str]) -> tuple[bool, Optional[str]]:
        """åœ°ç‚¹æ•°ã®æ¤œè¨¼"""
        return self._validators.validate_location_count(locations)
    
    def generate_with_progress(
        self, 
        locations: List[str], 
        llm_provider: str,
        view, 
        results_container
    ) -> BatchGenerationResult:
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆï¼ˆStreamlit UIé€£æºï¼‰"""
        import streamlit as st
        from app_session_manager import SessionManager
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¸€åº¦ã ã‘è¡¨ç¤º
        with results_container.container():
            st.markdown("### ğŸŒ¤ï¸ ç”Ÿæˆçµæœ")
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹UIä½œæˆ
        progress_bar, status_text = view.create_progress_ui()
        
        # ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        SessionManager.set_generating(True)
        
        # çµæœã‚’æ ¼ç´ã™ã‚‹å¤‰æ•°ã‚’äº‹å‰ã«åˆæœŸåŒ–
        all_results = []
        
        try:
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
            def progress_callback(idx: int, total: int, location: str) -> None:
                self._progress_handler.update_progress(
                    progress_bar, status_text, idx, total, location,
                    results_container, all_results, view
                )
            
            # ä¸¦åˆ—å‡¦ç†ã§è¤‡æ•°åœ°ç‚¹ã‚’å‡¦ç†
            with ThreadPoolExecutor(max_workers=3) as executor:
                # å„åœ°ç‚¹ã®å‡¦ç†ã‚’ã‚µãƒ–ãƒŸãƒƒãƒˆ
                future_to_location = {}
                for location in locations:
                    future = executor.submit(
                        self.generate_comment_for_location,
                        location,
                        llm_provider
                    )
                    future_to_location[future] = location
                
                # å®Œäº†ã—ãŸé †ã«çµæœã‚’å‡¦ç†
                completed_count = 0
                for future in as_completed(future_to_location):
                    location = future_to_location[future]
                    completed_count += 1
                    
                    # é€²æ—æ›´æ–°
                    progress_callback(completed_count - 1, len(locations), location)
                    
                    # çµæœå‡¦ç†
                    location_result = self._progress_handler.handle_completed_future(
                        future, location, all_results, results_container, view
                    )
            
            # æœ€çµ‚çµæœã‚’é›†è¨ˆ
            result = self._progress_handler.aggregate_results(all_results, locations)
            
            # å®Œäº†å‡¦ç†
            view.complete_progress(progress_bar, status_text, result['success_count'], len(locations))
            
            return result
            
        finally:
            SessionManager.set_generating(False)